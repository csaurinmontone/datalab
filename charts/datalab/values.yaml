# (TODO) Set your own domain name
domainName: "example.test"

# (TODO) Set your own SMTP server for Keycloak to use
smtpServer: |-
  {
    "password": "",
    "starttls": "",
    "auth": "",
    "port": "",
    "host": "",
    "from": "",
    "fromDisplayName": "",
    "ssl": "",
    "user": ""
  }

# Demo users and groups/projects to define
demo:
  enabled: true
  users:
    - name: jondoe
      password: jondoe
      groups:
        - g1
        - g2
    - name: janedoe
      password: janedoe
      groups:
        - g1
  projects:
    - name: g1
      members:
        - jondoe
        - janedoe
    - name: g2
      members:
        - jondoe

autoUpdatePolicy:
  schedule: "* */12 * * *"

alertThresholds:
  inactivityPeriod: 15d
  CpuRequestQuota: 0.5
  MemRequestQuota: 4
  CpuLimitsQuota: 30
  MemLimitsQuota: 64

###############################################################################
# Keycloak Chart configuration values (Chart version 15.1.0, codocentric)
# - Use PostgreSQL with Persistance Volume Claim data
# - PROXY_ADDRESS_FORWARDING due to being behind a reverse proxy
# - KUBE_PING for multiple replicas
# - Configure based on a secret with the realm configuration
# - (WARNING) !! Keycloak admin password is hardcoded here don't commit this file !!
###############################################################################
keycloak:
  # The number of replicas to create (has no effect if autoscaling enabled)
  replicas: 1 # Still some issues when trying out 2+ replicas

  affinity: |
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - topologyKey: kubernetes.io/hostname
  rbac:
    create: true
    rules:
      # RBAC rules for KUBE_PING
      - apiGroups:
          - ""
        resources:
          - pods
        verbs:
          - get
          - list

  # (TODO) Set PostgreSQL secrets for Keycloak to use
  postgresql:
    enabled: false
    postgresqlUsername: keycloak
    postgresqlPassword: keycloak
    postgresqlDatabase: keycloak

  # (TODO) Set Keycloak admin user and password
  kcUser: admin
  kcPassword: admin
  extraEnv: |
    - name: DB_VENDOR
      value: postgres
    - name: DB_ADDR
      value: postgres-headless
    - name: DB_PORT
      value: "5432"
    - name: DB_DATABASE
      value: keycloak
    - name: DB_USER
      value: keycloak
    - name: DB_PASSWORD
      value: keycloak
    - name: KEYCLOAK_USER
      value: {{ .Values.kcUser }}
    - name: KEYCLOAK_PASSWORD
      value: {{ .Values.kcUser }}
    - name: KEYCLOAK_IMPORT
      value: /realm/realm.json 
    - name: PROXY_ADDRESS_FORWARDING
      value: "true"
    - name: JAVA_OPTS
      value: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=50.0
        -Djava.net.preferIPv4Stack=true
        -Djboss.modules.system.pkgs=$JBOSS_MODULES_SYSTEM_PKGS
        -Djava.awt.headless=true 
        -Dkeycloak.profile=preview
        -Dkeycloak.profile.feature.upload_scripts=enabled
    - name: JGROUPS_DISCOVERY_PROTOCOL
      value: kubernetes.KUBE_PING
    - name: KUBERNETES_NAMESPACE
      valueFrom:
       fieldRef:
         apiVersion: v1
         fieldPath: metadata.namespace
    - name: CACHE_OWNERS_COUNT
      value: "2"
    - name: CACHE_OWNERS_AUTH_SESSIONS_COUNT
      value: "2"
    - name: KEYCLOAK_STATISTICS
      value: all
    - name: PROMETHEUS_PUSHGATEWAY_ADDRESS
      value: "http://datalab-prometheus-pushgateway.default.svc.cluster.local:9091"

  extraVolumes: |
    - name: realm-secret
      secret:
        secretName: {{ .Release.Name }}-realm-secret
    - name: deployments
      emptyDir: {}

  extraVolumeMounts: |
    - name: realm-secret
      mountPath: "/realm/"
      readOnly: true
    - name: deployments
      mountPath: /opt/jboss/keycloak/standalone/deployments
  
  extraInitContainers: |
    - name: extensions
      image: busybox
      imagePullPolicy: IfNotPresent
      command:
        - sh
      args:
        - -c
        - |
          echo "Copying extensions..."
          wget -O /deployments/keycloak-metrics-spi.jar https://github.com/aerogear/keycloak-metrics-spi/releases/download/2.5.1/keycloak-metrics-spi-2.5.1.jar
      volumeMounts:
        - name: deployments
          mountPath: /deployments

  extraContainers: |
    - name: keycloak-event-metrics-sidecar
      image: 054217936305.dkr.ecr.eu-central-1.amazonaws.com/keycloak-event-metrics-sidecar:latest
      imagePullPolicy: IfNotPresent
      env:
        - name: KEYCLOAK_SC__SVC_NAME
          value: http://localhost:8080
        - name: KEYCLOAK_ADMIN_USERNAME
          value: admin
        - name: KEYCLOAK_ADMIN_PASSWORD
          value: admin
      ports:
        - containerPort: 9991
          name: event-sidecar
          protocol: TCP

  service:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9991"
      prometheus.io/path: "metrics"
  
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
    rules:
      - host: "keycloak.example.test"
        paths:
          - path: /
            pathType: Prefix
    tls:
      - hosts:
        - keycloak.example.test

###############################################################################
# MinIO Chart configuration values (Chart version 9.1.0, bitnami)
# - Mode on standalone for prototype, preferred distributed for production
# - Persistence should be enabled with PVC for the data (further configuration is possible)
# - Configure Keycloak as id provider with environment variables
# - Post-install job created to create a policy in this MinIO server
# - (WARNING) !! MinIO root password is hardcoded here don't commit this file !!
###############################################################################
minio:
  enabled: true
  # Use distributed for more features
  mode: standalone
  # And you can configure the following
  # statefulset:
  #   replicaCount: 4 # Should be even and >= 4
  #   drivesPerNode: 1 # Total drives shoulb be % 4 = 0

  # Defaults to 8Gi per volume
  persistence:
    enabled: true
    # size: 1024Gi

  # (TODO) Set MinIO root credentials (password has to be bigger than 8 characters)
  accessKey:
    password: "admin"
  secretKey:
    password: "adminadmin"

  extraEnv:
    - name: MINIO_IDENTITY_OPENID_CONFIG_URL
      value: "https://keycloak.example.test/auth/realms/datalab-demo/.well-known/openid-configuration"
    - name: MINIO_IDENTITY_OPENID_CLIENT_ID
      value: minio
    - name: MINIO_DOMAIN
      value: "minio.example.test"
    - name: MINIO_IDENTITY_OPENID_CLAIM_NAME
      value: policy
    - name: MINIO_IDENTITY_OPENID_REDIRECT_URI
      value: https://minio-console.example.test/oauth_callback
    - name: MINIO_IDENTITY_OPENID_SCOPES
      value: openid,profile,email,roles

  ingress:
    enabled: true
    hostname: minio-console.example.test
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      nginx.ingress.kubernetes.io/preserve-trailing-slash: "true"

  apiIngress:
    enabled: true
    hostname: minio.example.test
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      nginx.ingress.kubernetes.io/preserve-trailing-slash: "true"

  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: "/minio/v2/metrics/cluster"
    prometheus.io/port: "9000"

###############################################################################
# Onyxia Chart configuration values (Chart version 1.3.0, inseefrlab)
# - Keep up to date with latest images if using InseeFrLab catalogs
# - API cluster admin has to be set to true to deploy on user's namespaces
# - ensure hostnames, client-id and realm configurations match the _realm-config.tpl
###############################################################################
onyxia:
  # Default values for onyxia-bis.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.

  imagePullSecrets: []

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    clusterAdmin: true # If true, give cluster admin permissions. Otherwise, be admin scoped to the namespace
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name:

  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/ingress.allow-http: "false"
    hosts:
      - host: datalab.example.test
    tls:  
      - hosts:
        - datalab.example.test

  ui:
    name: ui
    replicaCount: 1
    image:
      name: inseefrlab/onyxia-web
      version: latest # 482aa97b0156
      pullPolicy: Always
    podSecurityContext:
      {}
      # fsGroup: 2000
    securityContext:
      {}
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true
      # runAsUser: 1000
    service:
      type: ClusterIP
      port: 80
    resources:
      {}
      # We usually recommend not to specify default resources and to leave this as a conscious
      # choice for the user. This also increases chances charts run on environments with little
      # resources, such as Minikube. If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi

    nodeSelector: {}

    tolerations: []

    affinity: {}

    env:
      OIDC_REALM: datalab-demo
      OIDC_CLIENT_ID: onyxia-client
      OIDC_URL: https://keycloak.example.test/auth
      MINIO_URL: https://minio.example.test
      VAULT_URL: https://vault.example.test
      REACT_APP_DATA_CATALOG_URL: ckan
      REACT_APP_DOMAIN_URL: example.test

  api:
    name: api
    replicaCount: 1
    image:
      name: inseefrlab/onyxia-api
      version: latest # 19f8682347c2
      pullPolicy: Always
    podSecurityContext:
      {}
      # fsGroup: 2000
    securityContext:
      {}
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true
      # runAsUser: 1000
    service:
      type: ClusterIP
      port: 80
    resources:
      {}
      # We usually recommend not to specify default resources and to leave this as a conscious
      # choice for the user. This also increases chances charts run on environments with little
      # resources, such as Minikube. If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi
    nodeSelector: {}
    tolerations: []
    affinity: {}
    
    env:
      keycloak.realm: datalab-demo
      keycloak.auth-server-url: https://keycloak.example.test/auth
      authentication.mode: "openidconnect"
      springdoc.swagger-ui.oauth.clientId: onyxia-client
      catalog.refresh.ms: "300000"
      
    regions: [
      {
        "id": "demo",
        "name": "Demo",
        "description": "This is a demo region, feel free to try Onyxia !",     
        "onyxiaAPI": {
          "baseURL": ""
        },
        "services": {
          "type": "KUBERNETES",
          "initScript": "https://git.lab.sspcloud.fr/innovation/plateforme-onyxia/services-ressources/-/raw/master/onyxia-init.sh",
          "singleNamespace": false,
          "namespacePrefix": "user-",
          "usernamePrefix": "oidc-",
          "groupNamespacePrefix": "projet-",
          "groupPrefix": "oidc-",
          "authenticationMode": "admin",
          "quotas": { 
            "enabled": false,
            "allowUserModification": true,
            "default": {
              "requests.memory": "10Gi",
              "requests.cpu": "10",
              "limits.memory": "10Gi",
              "limits.cpu": "10",
              "requests.storage": "100Gi",
              "count/pods": "50"
            }
          },
          "defaultConfiguration": {
            "IPProtection": true,
            "networkPolicy": true
          },
          "expose": { "domain": "example.test" },
          "monitoring": { "URLPattern": "https://grafana.example.test/d/kYYgRWBMz/users-services?orgId=1&refresh=5s&var-namespace=$NAMESPACE&var-instance=$INSTANCE" },
          "cloudshell": {
            "catalogId": "inseefrlab-helm-charts-datascience",
            "packageName": "cloudshell"
          },
        },
        "data": { 
          "S3": { 
            "URL": "https://minio.example.test", 
            "monitoring": { 
              "URLPattern": "https://grafana.example.test/d/PhCwEJkMz/user-s3-storage?orgId=1&var-username=$BUCKET_ID"
            } 
          } 
        },
        "auth": { "type": "openidconnect" },
        "location": { "lat": 48.8164, "long": 2.3174, "name": "Montrouge (France)" }
      }
    ]

    catalogs: [
      {
        "id": "inseefrlab-helm-charts-datascience",
        "name": "Inseefrlab datascience",
        "description": "Services for datascientists. https://github.com/InseeFrLab/helm-charts-datascience",
        "maintainer": "innovation@insee.fr",
        "location": "https://inseefrlab.github.io/helm-charts-datascience",
        "status": "PROD",
        "type": "helm",
      }
    ]

###############################################################################
# Vault Chart (Chart version 0.18.0, HashiCorp)
# - It is necessary to init, unseal and configure the Vault after deployment
# - To use with Onyxia it is necessary to have CORS headers
###############################################################################
vault:
  server:
    enabled: true
    
    ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: nginx
        nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
        nginx.ingress.kubernetes.io/preserve-trailing-slash: "true"

      # When HA mode is enabled and K8s service registration is being used,
      # configure the ingress to point to the Vault active service.
      activeService: true
      hosts:
        - host: vault.example.test

    volumes:
      - name: config-vol
        configMap:
          name: vault-scripts
          defaultMode: 0777
          
    volumeMounts:
      - mountPath: /vault/scripts/
        name: config-vol
        readOnly: false

    dataStorage:
      size: 5Gi

###############################################################################
# Prometheus Chart (Chart version 15.0.1, Prometheus Community)
# - It is necessary to define the alertmanager.yml configuration first
###############################################################################
prometheus:
  alertmanager:
    enabled: true
    useClusterRole: true
  nodeExporter:
    enabled: true
  pushgateway:
    enabled: true
  server:
    enabled: true   
    extraConfigmapMounts:
      - name: prometheus-alerts
        mountPath: /etc/config/alerts
        configMap: prometheus-alerts
        readOnly: true
  # (TODO) define your own alertmanager.yml configuration
  alertmanagerFiles:
    alertmanager.yml:
      global:
        resolve_timeout: 5m
        http_config:
          follow_redirects: true
        smtp_from: example.test@example.test
        smtp_smarthost: smtp.example.test:587
        smtp_auth_username: example.test@example.test
        smtp_auth_password: example-password
        smtp_require_tls: true
      route:
        receiver: default-receiver
        continue: false
        group_wait: 10s
        group_interval: 5m
        repeat_interval: 3h
      receivers:
        - name: default-receiver
          email_configs:
            - to: diogom.o.moreira@gmail.com
            #- to: luismferreira@deloitte.pt
      templates: []
  
  serverFiles:
    prometheus.yml:
      rule_files:
        - /etc/config/rules/*.yml
        - /etc/config/alerts/*.yml


###############################################################################
# Grafana Chart (Chart version 6.17.10, Grafana)
# - Configured Prometheus as data source for Grafana
# - Configured Keycloak SSO in the grafana.ini
# - Import dashboards from labeled configmaps with the sidecar
###############################################################################
grafana:
  enabled: true

  # (TODO) Place your own admin credentials here
  adminUser: admin
  adminPassword: strongpassword
  
  ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: nginx
        nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
        nginx.ingress.kubernetes.io/preserve-trailing-slash: "true"
      hosts:
        - grafana.example.test
      tls:
        - hosts:
            - grafana.example.test

  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
    datasources:
      enabled: true

  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://{{ .Release.Name }}-prometheus-server.{{ .Release.Namespace }}.svc.cluster.local
          access: proxy
          isDefault: true
          jsonData:
            timeInterval: 30s

  dashboardProviders:
    default-provider.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          folderUid: ''
          type: file
          disableDeletion: false
          updateIntervalSeconds: 10
          allowUiUpdates: true 
          options:
            path: /var/lib/grafana/dashboards
            foldersFromFilesStructure: true

  dashboards:
    default:
      k8s-stats:
        # https://grafana.com/grafana/dashboards/10000
        gnetId: 10000
        revision: 1
        datasource: Prometheus
      keycloak-stats:
        gnetId: 10441
        revision: 1
        datasource: Prometheus
      nginx-ingress-stats:
        gnetId: 9614
        revision: 1
        datasource: Prometheus


  grafana.ini:
    server:
      root_url: https://grafana.example.test
    auth.generic_oauth:
      enabled: true
      scopes: "openid profile email"
      auth_url: https://keycloak.example.test/auth/realms/datalab-demo/protocol/openid-connect/auth
      token_url: https://keycloak.example.test/auth/realms/datalab-demo/protocol/openid-connect/token
      api_url: https://keycloak.example.test/auth/realms/datalab-demo/protocol/openid-connect/userinfo
      client_id: grafana
      signout_redirect_url: https://grafana.example.test


###############################################################################
# Ckan Chart
# - !! TODO !! Create your own CKAN image if you want to use Keycloak SSO
###############################################################################
ckan:
  clientsecret: your-client-secret

  image:
    repository: # (TODO) place your own image here! 
    tag: latest
    pullPolicy: Always
  
  # DBDeploymentName -- Variable for name override for postgres deployment
  DBDeploymentName: &DBDeploymentName postgres
  # DBHost -- Variable for name of headless svc from postgres deployment
  DBHost: &DBHost postgres-headless
  # MasterDBName -- Variable for name of the master user database in PostgreSQL
  MasterDBName: &MasterDBName ckan
  # MasterDBUser -- Variable for master user name for PostgreSQL
  MasterDBUser: &MasterDBUser postgres
  # MasterDBPass -- Variable for password for the master user in PostgreSQL
  MasterDBPass: &MasterDBPass postgres

  # CkanDBName -- Variable for name of the database used by CKAN
  CkanDBName: &CkanDBName ckan_default
  # CkanDBUser -- Variable for username for the owner of the CKAN database
  CkanDBUser: &CkanDBUser ckan_default
  # CkanDBPass -- Variable for password for the CKAN database owner
  CkanDBPass: &CkanDBPass ckan_default
  # DatastoreDBName -- Variable for name of the database used by Datastore
  DatastoreDBName: &DatastoreDBName datastore_default
  # DatastoreRWDBUser -- Variable for username for the user with write access to the datastore database
  DatastoreRWDBUser: &DatastoreRWDBUser datastorerw
  # DatastoreRWDBPass -- Variable for password for the datastore database user with write access
  DatastoreRWDBPass: &DatastoreRWDBPass datastorerw
  # DatastoreRODBUser -- Variable for username for the user with read access to the datastore database
  DatastoreRODBUser: &DatastoreRODBUser datastorero
  # DatastoreRODBPass -- Variable for password for the datastore database user with read access
  DatastoreRODBPass: &DatastoreRODBPass datastorero


  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      nginx.ingress.kubernetes.io/preserve-trailing-slash: "true"
      kubernetes.io/ingress.allow-http: "false"
      kubernetes.io/tls-acme: "true"
    hosts:
      - host: ckan.example.test
        paths: [/]
    tls: 
      - hosts:
          - ckan.example.test
  
  ckan:
    siteUrl: "https://ckan.example.test"

    psql:
      # ckan.psql.runOnAzure -- Set to true to run on Azure (if true wont run on anything other then azure) set to false to run on other platforms
      runOnAzure: false
      # ckan.psql.initialize -- Flag whether to initialize the PostgreSQL instance with the provided users and databases
      initialize: true
      # ckan.psql.masterUser -- PostgreSQL master username
      masterUser: *MasterDBUser
      # ckan.psql.masterPassword -- PostgreSQL master user password
      masterPassword: *MasterDBPass
      # ckan.psql.masterDatabase -- PostgreSQL database for the master user
      masterDatabase: *MasterDBName
    db:
      # ckan.db.ckanDbUrl -- Url of the PostgreSQL server where the CKAN database is hosted
      ckanDbUrl: *DBHost
      # ckan.db.ckanDbName -- Name of the database to be used by CKAN
      ckanDbName: *CkanDBName
      # ckan.db.ckanDbUser -- Username of the database to be used by CKAN
      ckanDbUser: *CkanDBUser
      # ckan.db.ckanDbPassword -- Password of the user for the database to be used by CKAN
      ckanDbPassword: *CkanDBPass
    datastore:
      # ckan.datastore.RwDbUrl -- Url of the PostgreSQL server where the datastore database is hosted
      RwDbUrl: *DBHost
      # ckan.datastore.RwDbName -- Name of the database to be used for Datastore
      RwDbName: *DatastoreDBName
      # ckan.datastore.RwDbUser -- Username for the datastore database with write permissions
      RwDbUser: *DatastoreRWDBUser
      # ckan.datastore.RwDbPassword -- Password for the datastore write permissions user
      RwDbPassword: *DatastoreRWDBPass
      # ckan.datastore.RoDbUrl -- Url of the PostgreSQL server where the datastore database is hosted
      RoDbUrl: *DBHost
      # ckan.datastore.RoDbName -- Name of the database to be used for Datastore
      RoDbName: *DatastoreDBName
      # ckan.datastore.RoDbUser -- Username for the datastore database with read permissions
      RoDbUser: *DatastoreRODBUser
      # ckan.datastore.RoDbPassword -- Password for the datastore read permissions user
      RoDbPassword: *DatastoreRODBPass

  postgresql:
    # postgresql.enabled -- Flag to control whether to deploy PostgreSQL
    enabled: false
    persistence:
      # postgresql.persistence.size -- Size of the PostgreSQL pvc
      size: 1Gi

    # postgresql.fullnameOverride -- Name override for the PostgreSQL deployment
    fullnameOverride: *DBDeploymentName
    # postgresql.pgPass -- Password for the master PostgreSQL user.
    # Feeds into the `postgrescredentials` secret that is provided to the PostgreSQL chart
    pgPass: *MasterDBPass

###############################################################################
# PostgreSQL Chart
# - Configure postgresql to be used as a common DB or do it as sub dependencies
#   on services and disable this one.
###############################################################################
postgresql:
  # postgresql.enabled -- Flag to control whether to deploy PostgreSQL
  enabled: true

  global:
    postgresql:
      postgresqlDatabase: "user"
      postgresqlUsername: "user"
      postgresqlPassword: "user"
      servicePort: 5432

  persistence:
    size: 1Gi

  fullnameOverride: *DBDeploymentName
  pgPass: *MasterDBPass

  postgresqlPostgresPassword: "postgres"

  initdbScriptsSecret: "secret-basic-auth" 
  initdbUser: "postgres"
  initdbPassword: "postgres"
